{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalesPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0          60       RL         65.0     8450   Pave  None      Reg   \n",
       "1          20       RL         80.0     9600   Pave  None      Reg   \n",
       "2          60       RL         68.0    11250   Pave  None      IR1   \n",
       "3          70       RL         60.0     9550   Pave  None      IR1   \n",
       "4          60       RL         84.0    14260   Pave  None      IR1   \n",
       "\n",
       "  LandContour LotConfig LandSlope    ...     PoolArea PoolQC Fence  \\\n",
       "0         Lvl    Inside       Gtl    ...            0   None  None   \n",
       "1         Lvl       FR2       Gtl    ...            0   None  None   \n",
       "2         Lvl    Inside       Gtl    ...            0   None  None   \n",
       "3         Lvl    Corner       Gtl    ...            0   None  None   \n",
       "4         Lvl       FR2       Gtl    ...            0   None  None   \n",
       "\n",
       "  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition SalesPrice  \n",
       "0        None       0       2    2008        WD         Normal   208500.0  \n",
       "1        None       0       5    2007        WD         Normal   181500.0  \n",
       "2        None       0       9    2008        WD         Normal   223500.0  \n",
       "3        None       0       2    2006        WD        Abnorml   140000.0  \n",
       "4        None       0      12    2008        WD         Normal   250000.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data/kaggle/data_combined_cleaned.csv\")\n",
    "df = df.drop(columns=[\"Id\"])\n",
    "df = df[~df.SalesPrice.isnull()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 0 to 1459\n",
      "Data columns (total 79 columns):\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            1460 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1460 non-null object\n",
      "MasVnrArea       1460 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1460 non-null object\n",
      "BsmtCond         1460 non-null object\n",
      "BsmtExposure     1460 non-null object\n",
      "BsmtFinType1     1460 non-null object\n",
      "BsmtFinSF1       1460 non-null float64\n",
      "BsmtFinType2     1460 non-null object\n",
      "BsmtFinSF2       1460 non-null float64\n",
      "BsmtUnfSF        1460 non-null float64\n",
      "TotalBsmtSF      1460 non-null float64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1460 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null float64\n",
      "BsmtHalfBath     1460 non-null float64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      1460 non-null object\n",
      "GarageType       1460 non-null object\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageFinish     1460 non-null object\n",
      "GarageCars       1460 non-null float64\n",
      "GarageArea       1460 non-null float64\n",
      "GarageQual       1460 non-null object\n",
      "GarageCond       1460 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           1460 non-null object\n",
      "Fence            1460 non-null object\n",
      "MiscFeature      1460 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalesPrice       1460 non-null float64\n",
      "dtypes: float64(12), int64(25), object(42)\n",
      "memory usage: 912.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.8810679185868064\n",
      "R2 on train: 0.9375912824998169\n",
      "RMSE on test: 0.14992302580448208\n",
      "RMSE on train: 0.09563404287838835\n"
     ]
    }
   ],
   "source": [
    "target = \"SalesPrice\"\n",
    "X = df.drop(columns=[target]) # Features\n",
    "y = np.log(df[target]) # target variable\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True) # One hot encoding\n",
    "\n",
    "# Randomly split the data into training and test test. \n",
    "# Keeping 30% of the records in test set.\n",
    "# random_state creates a reproducible set of random samples \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y\n",
    "                                , test_size = 0.3, random_state = 1)\n",
    "\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"linear_regression\", linear_model.LinearRegression()),\n",
    "    (\"Lasso\", linear_model.Lasso(alpha=0.001, max_iter=2000)),\n",
    "    (\"Ridge\", linear_model.Ridge(alpha=100.1, max_iter=2000)),\n",
    "    (\"ElasticNet\", linear_model.ElasticNet(alpha=0.01, l1_ratio=0.1, max_iter=2000, random_state=1))\n",
    "]\n",
    "\n",
    "scores = []\n",
    "for label, est in models:\n",
    "    pipe = pipeline.Pipeline([\n",
    "        (\"poly\", preprocessing.PolynomialFeatures(degree=1, include_bias=False)),\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"est\", est)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = pipe.predict(X_train)\n",
    "    y_test_pred = pipe.predict(X_test)\n",
    "    r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "    r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "    scores.append((label, r2_test, r2_train))\n",
    "    \n",
    "    \n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a271992b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = pd.DataFrame(scores).iloc[1:, :]\n",
    "summary.index = summary.iloc[:, 0]\n",
    "summary = summary.iloc[:, 1:]\n",
    "summary.columns = [\"Test\", \"Training\"]\n",
    "summary.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.7922448728991167\n",
      "R2 on train: 0.7826768177764206\n",
      "RMSE on test: 0.19815028630288936\n",
      "RMSE on train: 0.17846083251475386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.135812</td>\n",
       "      <td>0.135812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>0.076007</td>\n",
       "      <td>0.076007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>0.058887</td>\n",
       "      <td>0.058887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>0.022187</td>\n",
       "      <td>0.022187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>0.021313</td>\n",
       "      <td>0.021313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MSZoning_RM</td>\n",
       "      <td>-0.017863</td>\n",
       "      <td>0.017863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.016605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fireplaces</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.012819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1stFlrSF</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>0.005620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature  coefficient       abs\n",
       "3    OverallQual     0.135812  0.135812\n",
       "15     GrLivArea     0.076007  0.076007\n",
       "25    GarageCars     0.058887  0.058887\n",
       "6   YearRemodAdd     0.022187  0.022187\n",
       "11   TotalBsmtSF     0.021313  0.021313\n",
       "39   MSZoning_RM    -0.017863  0.017863\n",
       "5      YearBuilt     0.016605  0.016605\n",
       "23    Fireplaces     0.012819  0.012819\n",
       "12      1stFlrSF     0.005620  0.005620"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"SalesPrice\"\n",
    "X = df.drop(columns=[target]) # Features\n",
    "y = np.log(df[target]) # target variable\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True) # One hot encoding\n",
    "\n",
    "# Randomly split the data into training and test test. \n",
    "# Keeping 30% of the records in test set.\n",
    "# random_state creates a reproducible set of random samples \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y\n",
    "                                , test_size = 0.3, random_state = 1)\n",
    "\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"poly\", preprocessing.PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    (\"scaler\", preprocessing.StandardScaler()),\n",
    "    (\"estimator\", linear_model.Lasso(alpha=0.05, max_iter=2000)) \n",
    "    # alpha: regularization parameter\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "est = pipe.steps[-1][-1]\n",
    "summary = pd.DataFrame({\"feature\": X.columns\n",
    "                        \n",
    "                        , \"coefficient\": est.coef_})\n",
    "summary[\"abs\"] = np.abs(summary.coefficient)\n",
    "summary = summary.sort_values(\"abs\", ascending = False)\n",
    "summary = summary[summary[\"abs\"] > 0.0]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "_, pvals_ = feature_selection.f_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pval</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.543610e-232</td>\n",
       "      <td>OverallQual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.502663e-147</td>\n",
       "      <td>GrLivArea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8.980028e-140</td>\n",
       "      <td>GarageCars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.673012e-121</td>\n",
       "      <td>GarageArea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.435435e-106</td>\n",
       "      <td>FullBath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.707153e-98</td>\n",
       "      <td>TotalBsmtSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1.996594e-96</td>\n",
       "      <td>ExterQual_TA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.957045e-95</td>\n",
       "      <td>1stFlrSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.946855e-85</td>\n",
       "      <td>YearBuilt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.840149e-80</td>\n",
       "      <td>YearRemodAdd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pval       feature\n",
       "3    1.543610e-232   OverallQual\n",
       "15   1.502663e-147     GrLivArea\n",
       "25   8.980028e-140    GarageCars\n",
       "26   9.673012e-121    GarageArea\n",
       "18   7.435435e-106      FullBath\n",
       "11    4.707153e-98   TotalBsmtSF\n",
       "151   1.996594e-96  ExterQual_TA\n",
       "12    1.957045e-95      1stFlrSF\n",
       "5     2.946855e-85     YearBuilt\n",
       "6     3.840149e-80  YearRemodAdd"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvals = pd.DataFrame({\"pval\": pvals_, \"feature\": X.columns})\n",
    "pvals = pvals.sort_values(\"pval\")\n",
    "pvals.iloc[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.8648308786585401\n",
      "R2 on train: 0.9417975226233891\n",
      "RMSE on test: 0.15982973314248985\n",
      "RMSE on train: 0.09235504454648624\n"
     ]
    }
   ],
   "source": [
    "target = \"SalesPrice\"\n",
    "X = df.drop(columns=[target]) # Features\n",
    "y = np.log(df[target]) # target variable\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True) # One hot encoding\n",
    "\n",
    "# Randomly split the data into training and test test. \n",
    "# Keeping 30% of the records in test set.\n",
    "# random_state creates a reproducible set of random samples \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y\n",
    "                                , test_size = 0.3, random_state = 1)\n",
    "\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"poly\", preprocessing.PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    (\"scaler\", preprocessing.StandardScaler()),\n",
    "    (\"estimator\", linear_model.Lasso(alpha=0.001, max_iter=2000)) \n",
    "    # alpha: regularization parameter\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "\n",
    "\n",
    "est = pipe.steps[-1][-1]\n",
    "summary = pd.DataFrame({\"feature\": X.columns\n",
    "                        \n",
    "                        , \"coefficient\": est.coef_})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06534028, 0.0148992 , 0.11932297, 0.02461919, 0.00982281])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = - model_selection.cross_val_score(pipe, X_train, y_train, cv = 5\n",
    "                        , scoring = \"neg_mean_squared_error\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046800890598484746"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = np.mean(scores) # This is like 4.5 avg of 200 rating \n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
       "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95      , 1.06111111, 1.17222222, 1.28333333, 1.39444444,\n",
       "       1.50555556, 1.61666667, 1.72777778, 1.83888889, 1.95      ])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 1, 10) - 0.05 + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66958388, 1.30434417, 0.60454659, 0.90634167, 0.51709998,\n",
       "       0.99515028, 0.86125253, 0.69460795, 0.82611759, 0.98593448])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(10) +0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('poly', PolynomialFeatures(degree=1, include_bias=False, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=2000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ]), 'estimator__alpha': array([1.07291, 0.6944 , 1.43926, 1.38339, 0.61137, 0.81202, 1.47345,\n",
       "       1.14671, 1.34147, 0.86094])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"estimator__l1_ratio\": np.linspace(0, 1, 10),\n",
    "    \"estimator__alpha\": np.random.random(10) +0.5\n",
    "}\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"poly\", preprocessing.PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    (\"scaler\", preprocessing.StandardScaler()),\n",
    "    (\"estimator\", linear_model.ElasticNet(max_iter=2000)) \n",
    "    # alpha: regularization parameter\n",
    "])\n",
    "\n",
    "gsearch = model_selection.GridSearchCV(pipe, cv=5, param_grid=param_grid)\n",
    "gsearch.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8378038810773515"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__alpha': 0.8120175828705457, 'estimator__l1_ratio': 0.0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.8638097615822017\n",
      "R2 on train: 0.9033165100938427\n",
      "RMSE on test: 0.16043230346186596\n",
      "RMSE on train: 0.1190326345573211\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = gsearch.predict(X_train)\n",
    "y_test_pred = gsearch.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gsearch, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1632\r\n",
      "-rw-r--r--@ 1 abasar  staff   9.3K Oct 22 17:24 Day 1 - Spark.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff   170K Oct 22 16:26 Day 1 - handle null.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff   143K Oct 22 11:36 Day 1 - pandas.ipynb\r\n",
      "-rw-r--r--@ 1 abasar  staff    59K Oct 22 13:48 Day 1 - top 10 movies.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff   247K Oct 22 15:04 Day 1 - visualization.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff    47K Oct 23 15:34 Day 2 - regression.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff    57K Oct 23 16:51 day 2 - House price prediction problem.ipynb\r\n",
      "-rw-r--r--  1 abasar  staff    31K Oct 23 16:51 model.pkl\r\n",
      "-rw-r--r--  1 abasar  staff    20K Oct 22 14:23 plt.jpg\r\n",
      "-rw-r--r--@ 1 abasar  staff    12K Oct 22 14:31 plt.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    model_reloaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('poly', PolynomialFeatures(degree=1, include_bias=False, interaction_only=False)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('estimator', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=2000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'estimator__l1_ratio': array([0.     , 0.11111, 0.22222, 0.33333, 0.44444, 0.55556, 0.66667,\n",
       "       0.77778, 0.88889, 1.     ]), 'estimator__alpha': array([1.07291, 0.6944 , 1.43926, 1.38339, 0.61137, 0.81202, 1.47345,\n",
       "       1.14671, 1.34147, 0.86094])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.8638097615822017\n",
      "R2 on train: 0.9033165100938427\n",
      "RMSE on test: 0.16043230346186596\n",
      "RMSE on train: 0.1190326345573211\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model_reloaded.predict(X_train)\n",
    "y_test_pred = model_reloaded.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 258)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.873763</td>\n",
       "      <td>0.624479</td>\n",
       "      <td>0.119034</td>\n",
       "      <td>0.643952</td>\n",
       "      <td>-0.555344</td>\n",
       "      <td>0.183854</td>\n",
       "      <td>-0.411578</td>\n",
       "      <td>0.629676</td>\n",
       "      <td>0.801004</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062684</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>-0.297308</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>0.38846</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>8.193493</td>\n",
       "      <td>-2.177515</td>\n",
       "      <td>-0.301189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081557</td>\n",
       "      <td>-0.150423</td>\n",
       "      <td>0.355137</td>\n",
       "      <td>0.643952</td>\n",
       "      <td>-0.555344</td>\n",
       "      <td>0.549935</td>\n",
       "      <td>0.173040</td>\n",
       "      <td>0.161327</td>\n",
       "      <td>1.325697</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062684</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>-0.297308</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>0.38846</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>-0.122048</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>-0.301189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.873763</td>\n",
       "      <td>0.409229</td>\n",
       "      <td>-0.169196</td>\n",
       "      <td>-0.831651</td>\n",
       "      <td>-0.555344</td>\n",
       "      <td>-0.381907</td>\n",
       "      <td>-1.239787</td>\n",
       "      <td>-0.197162</td>\n",
       "      <td>-0.973886</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062684</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>-0.297308</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-2.57427</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>-0.122048</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>-0.301189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.320387</td>\n",
       "      <td>0.409229</td>\n",
       "      <td>0.565560</td>\n",
       "      <td>-0.093850</td>\n",
       "      <td>2.109264</td>\n",
       "      <td>-1.313748</td>\n",
       "      <td>-1.726969</td>\n",
       "      <td>-0.578780</td>\n",
       "      <td>0.112208</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062684</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>-0.297308</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>0.38846</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>-0.122048</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>-0.301189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.634933</td>\n",
       "      <td>-0.667024</td>\n",
       "      <td>-0.508594</td>\n",
       "      <td>-2.307255</td>\n",
       "      <td>-3.219951</td>\n",
       "      <td>-1.047508</td>\n",
       "      <td>-0.947478</td>\n",
       "      <td>-0.578780</td>\n",
       "      <td>-0.973886</td>\n",
       "      <td>-0.277569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062684</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>-0.297308</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>0.38846</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>-0.088823</td>\n",
       "      <td>-0.122048</td>\n",
       "      <td>0.459239</td>\n",
       "      <td>-0.301189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.873763  0.624479  0.119034  0.643952 -0.555344  0.183854 -0.411578   \n",
       "1  0.081557 -0.150423  0.355137  0.643952 -0.555344  0.549935  0.173040   \n",
       "2 -0.873763  0.409229 -0.169196 -0.831651 -0.555344 -0.381907 -1.239787   \n",
       "3  0.320387  0.409229  0.565560 -0.093850  2.109264 -1.313748 -1.726969   \n",
       "4 -0.634933 -0.667024 -0.508594 -2.307255 -3.219951 -1.047508 -0.947478   \n",
       "\n",
       "        7         8         9      ...          248       249       250  \\\n",
       "0  0.629676  0.801004 -0.277569    ...    -0.062684 -0.054259 -0.297308   \n",
       "1  0.161327  1.325697 -0.277569    ...    -0.062684 -0.054259 -0.297308   \n",
       "2 -0.197162 -0.973886 -0.277569    ...    -0.062684 -0.054259 -0.297308   \n",
       "3 -0.578780  0.112208 -0.277569    ...    -0.062684 -0.054259 -0.297308   \n",
       "4 -0.578780 -0.973886 -0.277569    ...    -0.062684 -0.054259 -0.297308   \n",
       "\n",
       "        251      252       253       254       255       256       257  \n",
       "0 -0.044281  0.38846 -0.044281 -0.088823  8.193493 -2.177515 -0.301189  \n",
       "1 -0.044281  0.38846 -0.044281 -0.088823 -0.122048  0.459239 -0.301189  \n",
       "2 -0.044281 -2.57427 -0.044281 -0.088823 -0.122048  0.459239 -0.301189  \n",
       "3 -0.044281  0.38846 -0.044281 -0.088823 -0.122048  0.459239 -0.301189  \n",
       "4 -0.044281  0.38846 -0.044281 -0.088823 -0.122048  0.459239 -0.301189  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_std).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.429291e-17</td>\n",
       "      <td>-1.738118e-18</td>\n",
       "      <td>-5.833559e-17</td>\n",
       "      <td>5.127449e-17</td>\n",
       "      <td>-3.463201e-16</td>\n",
       "      <td>3.268097e-15</td>\n",
       "      <td>-3.534681e-15</td>\n",
       "      <td>8.994762e-17</td>\n",
       "      <td>2.775558e-16</td>\n",
       "      <td>1.901067e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.001009e-16</td>\n",
       "      <td>1.895907e-16</td>\n",
       "      <td>-7.397866e-17</td>\n",
       "      <td>2.351484e-16</td>\n",
       "      <td>1.121086e-16</td>\n",
       "      <td>1.744229e-16</td>\n",
       "      <td>1.584132e-16</td>\n",
       "      <td>-2.881203e-16</td>\n",
       "      <td>4.302929e-16</td>\n",
       "      <td>4.942774e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "      <td>1.000490e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.737627e-01</td>\n",
       "      <td>-2.130727e+00</td>\n",
       "      <td>-8.966689e-01</td>\n",
       "      <td>-3.782858e+00</td>\n",
       "      <td>-3.219951e+00</td>\n",
       "      <td>-3.310552e+00</td>\n",
       "      <td>-1.726969e+00</td>\n",
       "      <td>-5.787801e-01</td>\n",
       "      <td>-9.738860e-01</td>\n",
       "      <td>-2.775694e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.268391e-02</td>\n",
       "      <td>-5.425922e-02</td>\n",
       "      <td>-2.973078e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>-2.574270e+00</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>-8.882312e-02</td>\n",
       "      <td>-1.220481e-01</td>\n",
       "      <td>-2.177515e+00</td>\n",
       "      <td>-3.011894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.737627e-01</td>\n",
       "      <td>-4.517733e-01</td>\n",
       "      <td>-2.969731e-01</td>\n",
       "      <td>-8.316513e-01</td>\n",
       "      <td>-5.553438e-01</td>\n",
       "      <td>-5.815870e-01</td>\n",
       "      <td>-8.500417e-01</td>\n",
       "      <td>-5.787801e-01</td>\n",
       "      <td>-9.738860e-01</td>\n",
       "      <td>-2.775694e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.268391e-02</td>\n",
       "      <td>-5.425922e-02</td>\n",
       "      <td>-2.973078e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>3.884597e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>-8.882312e-02</td>\n",
       "      <td>-1.220481e-01</td>\n",
       "      <td>4.592390e-01</td>\n",
       "      <td>-3.011894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.572726e-01</td>\n",
       "      <td>-2.127231e-02</td>\n",
       "      <td>-1.082536e-01</td>\n",
       "      <td>-9.384953e-02</td>\n",
       "      <td>-5.553438e-01</td>\n",
       "      <td>5.073419e-02</td>\n",
       "      <td>4.166310e-01</td>\n",
       "      <td>-5.787801e-01</td>\n",
       "      <td>-1.155908e-01</td>\n",
       "      <td>-2.775694e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.268391e-02</td>\n",
       "      <td>-5.425922e-02</td>\n",
       "      <td>-2.973078e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>3.884597e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>-8.882312e-02</td>\n",
       "      <td>-1.220481e-01</td>\n",
       "      <td>4.592390e-01</td>\n",
       "      <td>-3.011894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.203874e-01</td>\n",
       "      <td>4.092287e-01</td>\n",
       "      <td>9.445570e-02</td>\n",
       "      <td>6.439522e-01</td>\n",
       "      <td>3.328587e-01</td>\n",
       "      <td>9.825760e-01</td>\n",
       "      <td>9.038129e-01</td>\n",
       "      <td>3.796008e-01</td>\n",
       "      <td>5.710454e-01</td>\n",
       "      <td>-2.775694e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.268391e-02</td>\n",
       "      <td>-5.425922e-02</td>\n",
       "      <td>-2.973078e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>3.884597e-01</td>\n",
       "      <td>-4.428074e-02</td>\n",
       "      <td>-8.882312e-02</td>\n",
       "      <td>-1.220481e-01</td>\n",
       "      <td>4.592390e-01</td>\n",
       "      <td>-3.011894e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.186348e+00</td>\n",
       "      <td>1.043990e+01</td>\n",
       "      <td>1.960376e+01</td>\n",
       "      <td>2.857357e+00</td>\n",
       "      <td>2.997466e+00</td>\n",
       "      <td>1.282097e+00</td>\n",
       "      <td>1.196122e+00</td>\n",
       "      <td>8.672558e+00</td>\n",
       "      <td>1.121283e+01</td>\n",
       "      <td>8.665800e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.595306e+01</td>\n",
       "      <td>1.843005e+01</td>\n",
       "      <td>3.363518e+00</td>\n",
       "      <td>2.258318e+01</td>\n",
       "      <td>3.884597e-01</td>\n",
       "      <td>2.258318e+01</td>\n",
       "      <td>1.125833e+01</td>\n",
       "      <td>8.193493e+00</td>\n",
       "      <td>4.592390e-01</td>\n",
       "      <td>3.320170e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean   9.429291e-17 -1.738118e-18 -5.833559e-17  5.127449e-17 -3.463201e-16   \n",
       "std    1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00   \n",
       "min   -8.737627e-01 -2.130727e+00 -8.966689e-01 -3.782858e+00 -3.219951e+00   \n",
       "25%   -8.737627e-01 -4.517733e-01 -2.969731e-01 -8.316513e-01 -5.553438e-01   \n",
       "50%   -1.572726e-01 -2.127231e-02 -1.082536e-01 -9.384953e-02 -5.553438e-01   \n",
       "75%    3.203874e-01  4.092287e-01  9.445570e-02  6.439522e-01  3.328587e-01   \n",
       "max    3.186348e+00  1.043990e+01  1.960376e+01  2.857357e+00  2.997466e+00   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean   3.268097e-15 -3.534681e-15  8.994762e-17  2.775558e-16  1.901067e-17   \n",
       "std    1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00   \n",
       "min   -3.310552e+00 -1.726969e+00 -5.787801e-01 -9.738860e-01 -2.775694e-01   \n",
       "25%   -5.815870e-01 -8.500417e-01 -5.787801e-01 -9.738860e-01 -2.775694e-01   \n",
       "50%    5.073419e-02  4.166310e-01 -5.787801e-01 -1.155908e-01 -2.775694e-01   \n",
       "75%    9.825760e-01  9.038129e-01  3.796008e-01  5.710454e-01 -2.775694e-01   \n",
       "max    1.282097e+00  1.196122e+00  8.672558e+00  1.121283e+01  8.665800e+00   \n",
       "\n",
       "           ...                248           249           250           251  \\\n",
       "count      ...       1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean       ...       2.001009e-16  1.895907e-16 -7.397866e-17  2.351484e-16   \n",
       "std        ...       1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00   \n",
       "min        ...      -6.268391e-02 -5.425922e-02 -2.973078e-01 -4.428074e-02   \n",
       "25%        ...      -6.268391e-02 -5.425922e-02 -2.973078e-01 -4.428074e-02   \n",
       "50%        ...      -6.268391e-02 -5.425922e-02 -2.973078e-01 -4.428074e-02   \n",
       "75%        ...      -6.268391e-02 -5.425922e-02 -2.973078e-01 -4.428074e-02   \n",
       "max        ...       1.595306e+01  1.843005e+01  3.363518e+00  2.258318e+01   \n",
       "\n",
       "                252           253           254           255           256  \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean   1.121086e-16  1.744229e-16  1.584132e-16 -2.881203e-16  4.302929e-16   \n",
       "std    1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00  1.000490e+00   \n",
       "min   -2.574270e+00 -4.428074e-02 -8.882312e-02 -1.220481e-01 -2.177515e+00   \n",
       "25%    3.884597e-01 -4.428074e-02 -8.882312e-02 -1.220481e-01  4.592390e-01   \n",
       "50%    3.884597e-01 -4.428074e-02 -8.882312e-02 -1.220481e-01  4.592390e-01   \n",
       "75%    3.884597e-01 -4.428074e-02 -8.882312e-02 -1.220481e-01  4.592390e-01   \n",
       "max    3.884597e-01  2.258318e+01  1.125833e+01  8.193493e+00  4.592390e-01   \n",
       "\n",
       "                257  \n",
       "count  1.022000e+03  \n",
       "mean   4.942774e-17  \n",
       "std    1.000490e+00  \n",
       "min   -3.011894e-01  \n",
       "25%   -3.011894e-01  \n",
       "50%   -3.011894e-01  \n",
       "75%   -3.011894e-01  \n",
       "max    3.320170e+00  \n",
       "\n",
       "[8 rows x 258 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_std).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "      <td>1.022000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.953637e-17</td>\n",
       "      <td>9.093889e-17</td>\n",
       "      <td>1.229175e-16</td>\n",
       "      <td>9.994180e-18</td>\n",
       "      <td>1.075461e-17</td>\n",
       "      <td>-1.781571e-17</td>\n",
       "      <td>5.996508e-17</td>\n",
       "      <td>-1.194956e-16</td>\n",
       "      <td>-6.039961e-17</td>\n",
       "      <td>2.237827e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286693e-18</td>\n",
       "      <td>9.431491e-18</td>\n",
       "      <td>-1.236855e-18</td>\n",
       "      <td>2.463608e-17</td>\n",
       "      <td>1.236138e-17</td>\n",
       "      <td>1.497350e-17</td>\n",
       "      <td>-5.871224e-18</td>\n",
       "      <td>-1.724148e-17</td>\n",
       "      <td>-3.359362e-18</td>\n",
       "      <td>4.036432e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.119656e+00</td>\n",
       "      <td>2.850169e+00</td>\n",
       "      <td>2.724150e+00</td>\n",
       "      <td>2.559075e+00</td>\n",
       "      <td>2.373615e+00</td>\n",
       "      <td>2.235099e+00</td>\n",
       "      <td>2.025671e+00</td>\n",
       "      <td>2.003397e+00</td>\n",
       "      <td>1.887451e+00</td>\n",
       "      <td>1.875141e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.574838e-16</td>\n",
       "      <td>2.573140e-16</td>\n",
       "      <td>2.574840e-16</td>\n",
       "      <td>2.563046e-16</td>\n",
       "      <td>2.571898e-16</td>\n",
       "      <td>2.570508e-16</td>\n",
       "      <td>2.574200e-16</td>\n",
       "      <td>2.569085e-16</td>\n",
       "      <td>1.545188e-16</td>\n",
       "      <td>1.316077e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.236753e+01</td>\n",
       "      <td>-9.440973e+00</td>\n",
       "      <td>-3.432031e+00</td>\n",
       "      <td>-5.924086e+00</td>\n",
       "      <td>-6.694179e+00</td>\n",
       "      <td>-8.057743e+00</td>\n",
       "      <td>-6.139815e+00</td>\n",
       "      <td>-1.046043e+01</td>\n",
       "      <td>-5.305706e+00</td>\n",
       "      <td>-1.395758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.206811e-15</td>\n",
       "      <td>-1.930389e-15</td>\n",
       "      <td>-2.146200e-15</td>\n",
       "      <td>-1.517507e-15</td>\n",
       "      <td>-1.751796e-15</td>\n",
       "      <td>-1.867197e-15</td>\n",
       "      <td>-2.181489e-15</td>\n",
       "      <td>-2.132619e-15</td>\n",
       "      <td>-9.251287e-16</td>\n",
       "      <td>-1.145715e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.185322e+00</td>\n",
       "      <td>-2.170686e+00</td>\n",
       "      <td>-1.115534e+00</td>\n",
       "      <td>-1.811785e+00</td>\n",
       "      <td>-1.333684e+00</td>\n",
       "      <td>-1.653619e+00</td>\n",
       "      <td>-1.297904e+00</td>\n",
       "      <td>-1.128535e+00</td>\n",
       "      <td>-7.342490e-01</td>\n",
       "      <td>-8.632785e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.057132e-16</td>\n",
       "      <td>-9.400408e-17</td>\n",
       "      <td>-1.051810e-16</td>\n",
       "      <td>-8.387395e-17</td>\n",
       "      <td>-9.140451e-17</td>\n",
       "      <td>-1.045005e-16</td>\n",
       "      <td>-9.522074e-17</td>\n",
       "      <td>-1.098990e-16</td>\n",
       "      <td>-6.657653e-17</td>\n",
       "      <td>-4.511466e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-3.558915e-01</td>\n",
       "      <td>1.890238e-01</td>\n",
       "      <td>-3.082434e-01</td>\n",
       "      <td>-2.980131e-01</td>\n",
       "      <td>-2.452599e-01</td>\n",
       "      <td>1.781201e-01</td>\n",
       "      <td>-3.568633e-01</td>\n",
       "      <td>1.349725e-01</td>\n",
       "      <td>-9.494397e-02</td>\n",
       "      <td>8.720625e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.286693e-18</td>\n",
       "      <td>2.506061e-18</td>\n",
       "      <td>-1.236855e-18</td>\n",
       "      <td>1.943121e-17</td>\n",
       "      <td>5.939760e-18</td>\n",
       "      <td>1.313257e-17</td>\n",
       "      <td>-5.871224e-18</td>\n",
       "      <td>-1.724148e-17</td>\n",
       "      <td>-5.553650e-18</td>\n",
       "      <td>4.036432e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.645012e+00</td>\n",
       "      <td>1.859955e+00</td>\n",
       "      <td>3.784081e-01</td>\n",
       "      <td>1.210360e+00</td>\n",
       "      <td>7.411196e-01</td>\n",
       "      <td>1.418724e+00</td>\n",
       "      <td>9.136540e-01</td>\n",
       "      <td>1.184650e+00</td>\n",
       "      <td>5.354224e-01</td>\n",
       "      <td>8.449882e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060750e-16</td>\n",
       "      <td>9.925592e-17</td>\n",
       "      <td>9.361161e-17</td>\n",
       "      <td>1.179159e-16</td>\n",
       "      <td>1.033774e-16</td>\n",
       "      <td>1.127288e-16</td>\n",
       "      <td>8.439533e-17</td>\n",
       "      <td>8.217472e-17</td>\n",
       "      <td>5.333982e-17</td>\n",
       "      <td>4.860011e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.304485e+01</td>\n",
       "      <td>1.196429e+01</td>\n",
       "      <td>1.933322e+01</td>\n",
       "      <td>1.900405e+01</td>\n",
       "      <td>1.380053e+01</td>\n",
       "      <td>1.092898e+01</td>\n",
       "      <td>1.085253e+01</td>\n",
       "      <td>1.233467e+01</td>\n",
       "      <td>4.037238e+01</td>\n",
       "      <td>2.504245e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.666885e-15</td>\n",
       "      <td>3.571761e-15</td>\n",
       "      <td>3.508893e-15</td>\n",
       "      <td>3.911412e-15</td>\n",
       "      <td>2.984705e-15</td>\n",
       "      <td>2.599781e-15</td>\n",
       "      <td>2.317927e-15</td>\n",
       "      <td>2.367659e-15</td>\n",
       "      <td>2.479585e-15</td>\n",
       "      <td>1.658104e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean   4.953637e-17  9.093889e-17  1.229175e-16  9.994180e-18  1.075461e-17   \n",
       "std    4.119656e+00  2.850169e+00  2.724150e+00  2.559075e+00  2.373615e+00   \n",
       "min   -1.236753e+01 -9.440973e+00 -3.432031e+00 -5.924086e+00 -6.694179e+00   \n",
       "25%   -3.185322e+00 -2.170686e+00 -1.115534e+00 -1.811785e+00 -1.333684e+00   \n",
       "50%   -3.558915e-01  1.890238e-01 -3.082434e-01 -2.980131e-01 -2.452599e-01   \n",
       "75%    3.645012e+00  1.859955e+00  3.784081e-01  1.210360e+00  7.411196e-01   \n",
       "max    1.304485e+01  1.196429e+01  1.933322e+01  1.900405e+01  1.380053e+01   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean  -1.781571e-17  5.996508e-17 -1.194956e-16 -6.039961e-17  2.237827e-17   \n",
       "std    2.235099e+00  2.025671e+00  2.003397e+00  1.887451e+00  1.875141e+00   \n",
       "min   -8.057743e+00 -6.139815e+00 -1.046043e+01 -5.305706e+00 -1.395758e+01   \n",
       "25%   -1.653619e+00 -1.297904e+00 -1.128535e+00 -7.342490e-01 -8.632785e-01   \n",
       "50%    1.781201e-01 -3.568633e-01  1.349725e-01 -9.494397e-02  8.720625e-02   \n",
       "75%    1.418724e+00  9.136540e-01  1.184650e+00  5.354224e-01  8.449882e-01   \n",
       "max    1.092898e+01  1.085253e+01  1.233467e+01  4.037238e+01  2.504245e+01   \n",
       "\n",
       "           ...                248           249           250           251  \\\n",
       "count      ...       1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean       ...       1.286693e-18  9.431491e-18 -1.236855e-18  2.463608e-17   \n",
       "std        ...       2.574838e-16  2.573140e-16  2.574840e-16  2.563046e-16   \n",
       "min        ...      -2.206811e-15 -1.930389e-15 -2.146200e-15 -1.517507e-15   \n",
       "25%        ...      -1.057132e-16 -9.400408e-17 -1.051810e-16 -8.387395e-17   \n",
       "50%        ...       1.286693e-18  2.506061e-18 -1.236855e-18  1.943121e-17   \n",
       "75%        ...       1.060750e-16  9.925592e-17  9.361161e-17  1.179159e-16   \n",
       "max        ...       2.666885e-15  3.571761e-15  3.508893e-15  3.911412e-15   \n",
       "\n",
       "                252           253           254           255           256  \\\n",
       "count  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03  1.022000e+03   \n",
       "mean   1.236138e-17  1.497350e-17 -5.871224e-18 -1.724148e-17 -3.359362e-18   \n",
       "std    2.571898e-16  2.570508e-16  2.574200e-16  2.569085e-16  1.545188e-16   \n",
       "min   -1.751796e-15 -1.867197e-15 -2.181489e-15 -2.132619e-15 -9.251287e-16   \n",
       "25%   -9.140451e-17 -1.045005e-16 -9.522074e-17 -1.098990e-16 -6.657653e-17   \n",
       "50%    5.939760e-18  1.313257e-17 -5.871224e-18 -1.724148e-17 -5.553650e-18   \n",
       "75%    1.033774e-16  1.127288e-16  8.439533e-17  8.217472e-17  5.333982e-17   \n",
       "max    2.984705e-15  2.599781e-15  2.317927e-15  2.367659e-15  2.479585e-15   \n",
       "\n",
       "                257  \n",
       "count  1.022000e+03  \n",
       "mean   4.036432e-18  \n",
       "std    1.316077e-16  \n",
       "min   -1.145715e-15  \n",
       "25%   -4.511466e-17  \n",
       "50%    4.036432e-18  \n",
       "75%    4.860011e-17  \n",
       "max    1.658104e-15  \n",
       "\n",
       "[8 rows x 258 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_pca).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1214219e8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEFCAYAAADpIfy5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X2UXVWZ5/Hvk1RIwCAIFIQmgVLe1ShqNe3LOGOr3UJry8yIgk77Nrqy6NFWZ7lWN7p66Oj0vLim1R5HWjs2alBHoNFxRURtFGhBMVqEJBgK6PASUiSQyvtrVapSz/yx9/bsOrlVdW7VrbeT32etu+499+59zj5vz9lnn33ONXdHRETqZ850F0BERCaHAryISE0pwIuI1JQCvIhITSnAi4jUlAK8iEhNKcCLiNSUAryISE0pwIuI1FTbdE34tNNO846OjumavIjIrHT//fdvd/f2KmmnLcB3dHTQ1dU1XZMXEZmVzGxT1bRqohERqSkFeBGRmlKAFxGpKQV4EZGaUoAXEakpBXgRkZpSgBcRqSkFeBGRmlKAFxGpKQV4EZGaUoAXEampygHezOaa2QNmdluD3+ab2c1mttHMVptZRysLKSIizWumBv9RoHuE3z4A7HL384DPA5+ZaMFERGRiKgV4M1sMvBn4hxGSXAGsjJ9vBd5gZjbx4omIyHhVrcH/LfDnwNAIv58FbAZw90FgD3DqhEsnIiLjNmaAN7O3ANvc/f7RkjX4zhuMa5mZdZlZV29vbxPFFBGRZlWpwb8GeKuZPQncBLzezL5ZStMDLAEwszbgJGBneUTuvsLdO929s7290h+SiIjIOI0Z4N39E+6+2N07gKuBO939T0rJVgHvjZ+vjGmOqsGLiMjUGfdf9pnZp4Eud18F3AB8w8w2EmruV7eofCIiMk5NBXh3vxu4O36+Lvu+D3h7KwsmIiIToztZRURqSgFeRKSmFOBFRGpKAV5EpKYU4EVEakoBXkSkphTgRURqSgFeRKSmFOBFRGpKAV5EpKYU4EVEakoBXkSkphTgRURqSgFeRKSmFOBFRGpKAV5EpKaq/On2AjP7lZmtM7MNZvapBmneZ2a9ZrY2vj44OcUVEZGqqvyjUz/wenffb2bzgHvN7Ifu/stSupvd/cOtL6KIiIzHmAE+/nn2/jg4L770h9oiIjNcpTZ4M5trZmuBbcAd7r66QbK3mdl6M7vVzJa0tJQiItK0SgHe3Y+4+yXAYuBSM3txKcn3gQ53fwnwE2Blo/GY2TIz6zKzrt7e3omUW0RExtBULxp33w3cDVxW+n6Hu/fHwa8Arxgh/wp373T3zvb29nEUV0REqqrSi6bdzE6On48H3gg8XEpzZjb4VqC7lYUUEZHmVelFcyaw0szmEg4It7j7bWb2aaDL3VcBHzGztwKDwE7gfZNVYBERqcZCJ5mp19nZ6V1dXdMybRGR2crM7nf3zippdSeriEhNKcCLiNSUAryISE0pwIuI1JQCvIhITSnAi4jUlAK8iEhNKcCLiNSUAryISE0pwIuI1JQCvIhITSnAi4jUlAK8iEhNKcCLiNSUAryISE0pwIuI1FSVv+xbYGa/MrN1ZrbBzD7VIM18M7vZzDaa2Woz65iMwoqISHVVavD9wOvd/aXAJcBlZvbKUpoPALvc/Tzg88BnWltMERFp1pgB3oP9cXBefJX/5+8KYGX8fCvwBjOzlpVSRESaVqkN3szmmtlaYBtwh7uvLiU5C9gM4O6DwB7g1FYWVEREmlMpwLv7EXe/BFgMXGpmLy4laVRbP+rfvM1smZl1mVlXb29v86UVEZHKmupF4+67gbuBy0o/9QBLAMysDTgJ2Nkg/wp373T3zvb29nEVWEREqqnSi6bdzE6On48H3gg8XEq2Cnhv/HwlcKe7H1WDFxGRqdNWIc2ZwEozm0s4INzi7reZ2aeBLndfBdwAfMPMNhJq7ldPWolFRKSSMQO8u68HXtbg++uyz33A21tbNBERmQjdySoiUlMK8CIiNaUALyJSUwrwIiI1pQAvIlJTCvAiIjWlAC8iUlMK8CIiNaUALyJSUzMiwC9duXS6iyAiUjszIsCLiEjrKcCLiNSUAryISE0pwIuI1JQCvIhITSnAi4jUVJW/7FtiZneZWbeZbTCzjzZI8zoz22Nma+PrukbjEhGRqVPlL/sGgY+7+xozOxG438zucPeHSunucfe3jLcg3RddzMUPd483u4iIlIxZg3f3re6+Jn7eB3QDZ012wUREZGKaaoM3sw7C/7OubvDzq8xsnZn90Mxe1IKyiYjIBFRpogHAzBYC3wE+5u57Sz+vAc5x9/1m9kfA94DzG4xjGbAM4Oyzzx53oUVEZGyVavBmNo8Q3L/l7t8t/+7ue919f/x8OzDPzE5rkG6Fu3e6e2d7e/sEiy4iIqOp0ovGgBuAbnf/3AhpFsV0mNmlcbw7WllQERFpTpUmmtcA7wYeNLO18btPAmcDuPuXgSuBPzWzQeAQcLW7+ySUV0REKhozwLv7vYCNkeaLwBdbVSgREZk43ckqIlJTCvAiIjWlAC8iUlMK8CIiNaUALyJSUwrwIiI1pQAvIlJTCvAiIjU1IwP8Z68a92PlRUQkmpEBXkREJk4BXkSkphTgRURqSgFeRKSmFOBFRGpKAV5EpKYU4EVEakoBXkSkpqr8J+sSM7vLzLrNbIOZfbRBGjOzL5jZRjNbb2Yvn5ziiohIVVX+k3UQ+Li7rzGzE4H7zewOd38oS3M5cH58/R7wpfguIiLTZMwavLtvdfc18fM+oBs4q5TsCuBGD34JnGxmZ06kYD3X3jOR7CIix7ym2uDNrAN4GbC69NNZwOZsuIejDwKY2TIz6zKzrt7e3uZKKiIiTakc4M1sIfAd4GPuvrf8c4MsftQX7ivcvdPdO9vb25srqYiINKVSgDezeYTg/i13/26DJD3Akmx4MbBl4sUTEZHxqtKLxoAbgG53/9wIyVYB74m9aV4J7HH3rS0sp4iINKlKL5rXAO8GHjSztfG7TwJnA7j7l4HbgT8CNgIHgfe3vqgiItKMMQO8u99L4zb2PI0DH2pVoUREZOJmxZ2sP73zXBbdtXbshCIi8luzIsCLiEjzFOBFRGpKAV5EpKYU4EVEakoBXkSkphTgRURqSgFeRKSmZm+AX34SS1cune5SiIjMWLM3wIuIyKgU4EVEaqo2Af76a+6c7iKIiMwotQnwIiIyXK0C/Gevest0F0FEZMaoVYDPLV++fLqLICIyrWob4CE8ZlhE5FhV5S/7vmpm28zsNyP8/joz22Nma+PrutYXc/z0HHkROVZV+cu+rwNfBG4cJc097q4GcBGRGWTMGry7/wzYOQVlmXQd1/4Alp803cUQEZkSrWqDf5WZrTOzH5rZi0ZKZGbLzKzLzLp6e3tbNGkREWmkFQF+DXCOu78U+D/A90ZK6O4r3L3T3Tvb29tbMOmJ6b7o4ukugojIpJlwgHf3ve6+P36+HZhnZqdNuGRTRHfAikhdTTjAm9kiM7P4+dI4zh0THe906Ln2nukugohIy1TpJvlt4D7gQjPrMbMPmNk1ZnZNTHIl8BszWwd8Abja3X3yijy5li9frv7zIlILY3aTdPd3jvH7FwndKGup49of8OT/fPN0F0NEpGm1vpO1VTqu/cF0F0FEpGkK8E3Sv0iJyGyhAD8O6l4pIrOBAnwLqPeNiMxECvAtoscTi8hMowA/CRbdtVYXZkVk2inATwU94ExEpoEC/BRR7xsRmWoK8NNE/x8rIpNNAX4a5b1v9HgEEWk1BfgZJP97QV2kFZGJUoCfyZafpLZ7ERk3BfhZ5Ppr7lTbvYhUpgA/i+nRxiIyGgX4Gum49gdquxeR31KAr6Psxio9GE3k2FXlH52+ambbzOw3I/xuZvYFM9toZuvN7OWtL6ZMRP6/sz3X3qPn5ogcI6rU4L8OXDbK75cD58fXMuBLEy+WTCU17YjU05gB3t1/BuwcJckVwI0e/BI42czObFUBZeotXbl0WNPOZ696ix6JLDILtaIN/ixgczbcE787ipktM7MuM+vq7e1twaRluuQ3ZYnIzNSKAG8NvvNGCd19hbt3untne3t7CyYt02lYs46emCky47QiwPcAS7LhxcCWFoxXZpn8rtv8wq6ITI9WBPhVwHtib5pXAnvcfWsLxiuzXPmuW92UJTK1qnST/DZwH3ChmfWY2QfM7BozuyYmuR14HNgIfAX4T5NWWpn1jnqgmpp2RCZN21gJ3P2dY/zuwIdaViI5ZnVfdDF3vu56PvTl1093UURqQXeyyoyTN+3opiyR8VOAlxkvb7vXTVki1SnAy6yWbspSrx2RoynAS+3oeTsigQK81N6iu9aqWUeOSQrwckwqP29HpI4U4EXQA9WknhTgRRr46Z3nHv1ANd2UJbOMArxIE/S8HZlNFOBFJqB8U1bDmr/INFGAF5lEet6OTCcFeJEppJuyZCopwItMI92UJZNJAV5kBtDzdmQyKMCLzHC6KUvGSwFeZJbRTVlSVaUAb2aXmdkjZrbRzK5t8Pv7zKzXzNbG1wdbX1QRyeVt93rejjRS5S/75gLXA5cDLwTeaWYvbJD0Zne/JL7+ocXlFJFmLD9p2E1ZcmyqUoO/FNjo7o+7+2HgJuCKyS2WiLRa+U/Qpf6qBPizgM3ZcE/8ruxtZrbezG41syUtKZ2ItFTedp/33JF6qhLgrcF3Xhr+PtDh7i8BfgKsbDgis2Vm1mVmXb29vc2VVERaTo9VqLcqAb4HyGvki4EteQJ33+Hu/XHwK8ArGo3I3Ve4e6e7d7a3t4+nvCIySfRYhfqpEuB/DZxvZs83s+OAq4FVeQIzOzMbfCvQ3boiish0uf6aO9V2P4uNGeDdfRD4MPBjQuC+xd03mNmnzeytMdlHzGyDma0DPgK8b7IKLCLTJz0xU2aHtiqJ3P124PbSd9dlnz8BfKK1RRORmS71vX9ywbtg+Z5pLo2U6U5WEWkpPVZh5lCAF5GWyx+JrMcqTB8FeBGZdOXHKsjUUIAXkSlXfiSyHqswORTgRWRGyNvu1TWzNRTgRWRGUtv9xCnAi8isoEciN08BXkRmJz1WYUwK8CIya+ni7OgU4EWkFvTcnKMpwIuI1JQCvIjU1k/vPPeYvrFKAV5EjhnH2jPvFeBF5JjVfdHFw56bUzcK8CIimTo9814BXkRkFOXn5swmlQK8mV1mZo+Y2UYzu7bB7/PN7Ob4+2oz62h1QUVEZoKlK5fOmqadMQO8mc0FrgcuB14IvNPMXlhK9gFgl7ufB3we+EyrCyoiMlP1XHvPsEcizxRVavCXAhvd/XF3PwzcBFxRSnMFsDJ+vhV4g5lZ64opIjJ7zJTn5lQJ8GcBm7PhnvhdwzTxT7r3AKe2ooAiIjI+5u6jJzB7O/Amd/9gHH43cKm7/1mWZkNM0xOHH4tpdpTGtQxYFgcvBPLftwOnNTE8WXlmUlmOxfJrnmdfWY7F8k/nPD/H3dupoK1Cmh5gSTa8GNgyQpoeM2sDTgJ2lkfk7iuAFWnYzLqy3zqbGZ6sPDOpLMdi+TXPs68sx2L5p3meO6ioShPNr4Hzzez5ZnYccDWwqpRmFfDe+PlK4E4f69RAREQm1Zg1eHcfNLMPAz8G5gJfdfcNZvZpoMvdVwE3AN8ws42EmvvVk1loEREZW5UmGtz9duD20nfXZZ/7gLePY/orJjg8WXlmUlmOxfJrnmdfWY7F8k/nPFcy5kVWERGZnfSoAhGRmlKAFxGpqUpt8K1gZhcR7ng9C3DCweVn7v6P8dEHlwFvJjwS4Wpgi7v/xMzeBbwa6AZWuPvAVJVZRGQ2m5I2eDP7C+CdhMcc9ADvBv4N4QCzm9A7pxc4D+gjBP9+4CBwCHgYeB7whLu/q0VlOt3dt5nZqeUbsqbbeMo2VXmalaYRP8+4ZS3Tx8zOoKjwbXH3Z+P3Cwk39rzE3VeZ2aWE+2yeAS6Or+74us/dh8zsZcAFwEXAzcCbgIWEGHMeIY6sBx6omKcd2A+sBn7RqGyEjicvBToId++fT4hfjwCPVczzamAQeAJ4aoSyfRZ4VyzTGnf/YeVlPEUB/lHgRe4+YGYfAf4XYYG3Ac8hzNhNwJ/HLIcJK72NsBBuBnYBHwcuc/e7S+PPg0gHcA3w7wkbxXFxWncDZxA2jnmEg8jcOJ2hODwnDg8QNqZvAecArwVOAI6PeebFMrbF4aE4jfuBvwC+CZxIOCjdCrwt5tkPzI9lIk5rrLLB8Ka0I8DThAe6vQd4cQvzWHylcv06zs+H4zzMLc3PQDYej9PZkk3nd+N4fwMszZa1xTx9wNeBT42wM9xHuGnutXF5dwDbCNtCD/CrbGd4BXA6sDYu+1fGaZwUy7Qm5SGstwuB34t5hgjbYW8s04uAx4GfMULgIWwfKeh4XKab43DVPL9fnp8KZXt1nJ8H4vRWE7bNNxEqRRcQtrGJ5hlpGSwB9gH/epT52T3GdF4A/GH8fITwWJMFcV7vBzoJ2wgU21hukOGtD1uA3ymlcYqWgrRtzs3GO1YeYp45MU+jsiVDWZ58X6qaJ//cqGxHCPPcDzwG/NjdP0EV7j7pL0IN/Jz4+UFgXZyh/x0XyA5CkE8B4ElCwPc4U/2E/vVD8fUscAlhx+iL3/URNoaBOJxW1u7sc1rR5eGU/9E4zoFSmqHScMp3APgXQuAu/17O0xvz9BGC7b44X6OVLX23N67YnaU8R1qUZyjLsyEug7Hm/3B87Y/rbl8pbaNpPB7LMhDLdTD7bZCwPTSaVn9pnGmdDQE/GqGs+0t5hrLX3ji98nT6KA7w+XIZJASs8vrybDxHmshzpEHescrWX3pP0zpMsd23Ik95GaTy7Ynra6TtLZ+fKtNJ++lgts72Zb/vLI0r7ed7CZWPtI32Z2m2ZuVJZTlIiAF98btBigrkSHn2Ex4PcCArXz4PO7P8qex7Yp792bwdHiPPvgZlG2l+dhLOWHqA7sqxd4oC/GXARoqNd4AiwB0uzfSB+PsmimDQn63csQJpvhDTdPJ8h7I86wi1w/IO28/wDflwluc32YLPN9Zy4FybleMpwqlZvkPs4+ggXy7bU6Vx9pXyHJmkPIOl+RkqvZ5i+EEtzU/aUMtB60hc/3+XLc8B4O8ZvhOUp+XZ7xvid/+YjXukPGl9PxS/+3aDPP3Z8JEsz8H4+ipHB9p8O8h34INx/m9sIs+h+Go0PyOV7RBFZSffpvMAmALURPKkZdBLCFx5nnx7TftvPj+74riGRplO2q4OxHE8E6d9MBv3YxTbzoMMD3ZHCPFhS5xmyrOZIthuyJZrCtKHgf9cIU++/TbaTh+jCNAPcvR+0kyeND8jlW0olu15hCf7bovj/0WV2DslvWjc/UeE07PU1vQ3hHb4iwi18acpTmE2EWr3ZxKaMtooThvTaf2RbPRpgztIWIjE4fS+MU47BeIF2bQWUzxiIQX2g4QVsJFiR8tPB08lrAQIZyYDhJWzgXAEJ5ZvaZzOEcIp5nfjb0PxvScuiycpAl65bOn0MJ3FHI7zuJeiVtWKPAvi58PZMniA4nlCz1I036T52URxMEjz8zhFzWp7Kc/zKJqm2mI506n3njj/UKy7VAs6PQ5fEMe1OI5vG2FbyJdpyvP8OHxezNMZ8zyb5cmndziWD0Iz3PHAG+Nvu7K0h7M8/YTmn5RnIeGssmqeBfHVaH5GKltq3juBsD5T04hRrAcI62YiedIyOCmWaVf83ihqshDamsvzc1xMv22U6fxdNn/HAScTarJ5peAFFNvOebE8EPa9wZhnP0VTiBOWZSr/BbGsRnFQGSSsp9HypLLujHn6gXsZXhF9QUyT2vfT+nom5hkA/nmMPP3ZdNKB7PgGZUtNpl2EpucTCTGrUhPNlN7oZGY3ALcRLiQ8U/rt/wL/RAgsbcAphFP2duCPga8RFtgfEppF5lMECggbCIQF8AywiNDmdiSmPwf4AvAOQgBItY7jKBbqvPj+DPBcQpDqIpyBLIzjTxtt/g7hyLyFEOg7CW2TcxjejpeO2qm9P9VgugkbUaOypTb+1Fa+hXBg6Ypp3tvCPEmqaTxOODgsIdQe0jyk+ck3HiPUsjYDd8U87yCso31x/OXpbCKsxx8Df0JYvyfE3wZi2oPxu7QsHyRUDPYTDrYHKNbNYEyX2jTnxO8eJuxgBwjt4Yey6QyWpkMsx1pCu/oewkFmkOJAmPI8TXGRcIBwzeLlMU/7KHl+hyJYPlSan7HKlg5iDxKuSZwW854Yf0+1wv4J5jkcv/sVIfCdQQj2z6HQR9hH8vlJZ2tnxvkZaTrHUzTzzYnjaSNsB+cCfxXH8UDMuyim2xPLfxj4DqGd/764nFcQ1tlDhG3LCAfdBXG5PkPYz+6JZRwpz6ti+dKZ6X2EaxFPELaj5bFsWwiVBidcN5kTy7Ur5llLuPYzUp5z4/T2ESp69xLiR3l+fhiXwx6gz92/SUUz+k5WM3seIbC/hLBw5hAW8nbCSno1YWW0URw52ygu4m0nXMRbR7hy3UYI4ntimseAl8V0hwhnCp2EDTM9jvO5hB1sPWEjf35M+3PCzncx4eCyGOhx9/eY2Y2EDeT1hI1xZZzece5+lZndRjhyfwW4iqIW8QzhOsBFhKDihB3sZYSAeQphY5gfP58Yx3OIUPs6IS6Dp2L6Ewg74XcIB7kUbL5GcTDZRrgo/FqKnkxvIuy0cwlBZhFFLfBeQlA7g7Ah74lpF8ZpD8a0fYQdeQ7FGVD++8JY9t2EjfdRws76u8B1Md2+mDat98UUZ2qbCM0bG+O6uomwDfTGZT+HENgviWXZFJfBj2KeM4DvxTL1UDQlDBK2t7SjPhLLtxr4V8BfxjTpTGUgzsPzY57eWNafj5FnEyEoNJqfkcq2NS6fOcAvCIHijizP9+Ny/glw9gTypGXQRtjun43vqwnbyV/G+VhP2DbSNndBXAc/j/P63TidRRQPKMyncz9hG95EeJ7VQnffRA2Y2ekAsZdaOgs1d382GyZPkzqKtLQcMznAj8bM3h8/3kToXfN0HH5jfJ1CcdU81YRgeO07XaFPC6F8pd1Ln8mGWyGvDUPY2Y8vpRlieI25jxDgoWgeWkgROOYztvJ0UxPXIGF5zKdoXkkanbXkn9OZSV7mcvqULrVJnkKoVb+v3DNqNst34GwH/+1yKO30jHfHNrNhf6rj7jvy7xoNj2c6rWZmJxFqtO8mVEyabSoeIhxAvgF8inCNBXe/3MzyLoRXEWrR7RSVi+2Eg/FuiubIJTH9fkJl8FUUZ1unEpqh5lJUOOZTNE+mM38jbMtpGZ8e03+M8DemxDQfBf6WormyD/gc8NcU177SmWzqAbibUNFMFbafAn+aejaNZjYH+KcA3P3s9DlaRKipnU/R9JJqkU6osaada5BQi8yH52V50gWT1BUQQo3uwvjZKZqD0g6cNxmkC5oLKQ4yewm1ljmEDeg0ikA4RFHLfojwH7j9hA0qb8tNQfwRQtPTgmz4QsJGsICwE5zC0d3K9lGcNkPRTpjS9Md53kHR1JDGkdJsiNNqi+nT70fitPvjezfhLCedjZxMODVN42nmgJnat28kdK3cne/QpR18LqFJYlmcVmq73c7wHXoNYYeeR1h36bQ8dVFMO3d5h04HsNS+ewJhHa0nnAWldVrewR34EvARijb2JwhnmPMJ29sOwnpLzYcHY/7ULJnabNOBGIqDdppOqqzkDhK2//nxt28RmjxPyYb/GfgvhKacuYQmmXRWnJQrCOXhZg0Q9otuQndXCNuwUWzrDxPW2yBhXW4nnOkeoLgOcA+h+2YKajsIZ5t5xS1t26kCkypM+T6YmgPTNpoqXmn9DRDWTasrfemCcKp0pl5LabtYS9guBwj97P/tmGOcil40E+h9s57i6nyj3jJVXmlnSJ9TMEpHytRTJ7UNphU4RNGb4CBFEHwgDqcLKPcRdpqhbHg3xYXTfHiIcMqaPufz11eaTjfFhd9Bwqn/IYpuWIMUXTTz4XQhdZDQhn6I0L6X5nl/Nv00nJoA8uWUv6dlk/e0eTQb7qforZHWVXrvzuZpTTa9IeC/xuF+QuDelS3vnRTBbh3w/+LnHTHdVkLbfb6Ofhynm85GdjF8/adrDum7cg+LNL99pTx517U8b6Mug+N9DREOLCmApSbHQcL2k6Z3gGLbPELRFJYv100c3ZOlPK3yfpEPp95naXpHSq80nn2lcTwb8+ZdlgcJwTudbaZlm3pjpc4AfcB/p2iXfyS+0nDe62Siyzkt26Fs3FsZvh0cyPKsZ/gF0wdKafPu2ulieRr/3zC8u+i92fpMB/e0369heO+7NRTx4VCMiWvTa8Z0k5xAgH+WsENfTtjh98SNKnXpGqLYkNPwQFxoaYHuIATZcvByQi2gPJynWRNX9Lr4fiB+ty4u5AcJF0BS8BvKpr0/rph8eLwHqVRzHe8G3UUItGvjxnl8tqE8QLjB7AmO7uI22jgbfS7vRHmAKe80hwlnBykgl3foR7L3VgXRNN2RduiB0ncj7dCHKQ7y6QDxRFx26WBf3qHTTt5HODvrz17pALWG4QfH9H0aHiLUZFN5U9py5eDh0vCaOJ28y6NTHPSHRhhOwT71Hc8rNmm55MPrYnnSQSGV4eEszcGs7Knmnnp7HcjmuXzAT+vnSYqmkMOE9v60rB+N71vj+8b4vjlLs4WiK2vqsp22i7yPfEqTKj+7s3Gsi++py+JfE/avdLDN7/H4F4ouoCmg5/fqpMqlZ8vOs+HU+6efcKawPr2qxNApexbNON1GuBC0j1CDOyP7Ld0R1024CPlQHH6a0M7132K6PsLp8ArgFsKGMZfQVLCOcOFuX0x7H+F0PTXLpAueaXg3oUnm3Jh+N2Fj+o+EnjaPES6OvSf+/hhhA2w0/Ji7fxLAzE4gNLUkfYSDW/ounSqfR2juOTGWeSth5Z8el8fWuIwGCKezm4FH3P0+M7sgjdzdD5nZO7LhR80svzJ/LuFOyr2EZpZz4vRTl7EzCc1HqefMcwlNYjsIO9AzhLOH82LZ8uFr4jiPAH9GuHC3hOHNZMRho+j1coiih9QZMd3T8bv0f5VPENpXt8fvNsZp5s1o6QL8qYQkSnmrAAADl0lEQVSdLH03n6JZLimfsu8mtBnvivOcem7NITRZ/QGhuSDtuG2EJoLnUNy53RaXVWoyhKIp4OI4zdQ0k5pg0g5vhKYgp7jzM/UkS0FpLmE/yK+HpCayJ+OyTs2SvyTc8TsQ5+lxQm+ptB5OyZZX/p6aJF7A8GtWZ1A0IaXl53E8STrrSM1NeVNhfsdq+VpUcg5FcPwFoXLytjiNBwndkx+I6U6J8/5PhIvtpxO2mX7g38XxrSFchD4Y5++BuAz2UTSt3hGX0/Y4fF/87TFC/LiF0LT0JKHScgHFnd6p+6NT9JqDYp1Csa1sY/h1sd2EOHWIEA9eSDhYQtGldlSztg1eZqfYM+qvCAe5k2m+DX4vRVe31K6eduZ8B38jYcc5i+E7+BGG79APZsPHUezQr6XYwW8hBO+0Q/8sG07NGNcSLvhfRAjCg/H7ZykqBGknHyQcYCAEq9RBYC7FNY+0gz+PojaXzhBeThFY80BRlgeLfbGMv5/Su/vVZnbTbxduGH4p4RrBRXEaqR99s23wqTk03XORH4DSAWkn8D8I7f2LYp4NhIrCQYoebvkw8bvbgP9ACKQpzYG4bKqk2R6nv3+MPHmaqtPZSzjQn084aKaLpecTzqLmELbfy+OyeTx+t3GE6Wwn1Ni/Z2aXpQXs4f6iUSnAy4yR9YzC3b822nCVNOPJ04LxziN0G/0+YQfelg3/MSHIbSuleXoGlX8q8nwLeAvFWVOq9ecXifMebvkwDD+jadQrrkqa2ZTHCQfRKwmVo7Qs00FmRArwMmPkvaG81DuqPFwlzXjyTNZ4Vf5h36UeYc8SaqnpLuXUwwwa93BLXZ7TQ8rmcnSvuCppxjPe6cqzk6In1zOEg2BvXJbpjGZECvAypcxsPeFUNXV/a+V9BTK7pYuaqZunUzRFpW6LqQtpGh4YR5rxjHe68qRmyfmEYH8moZlni7tfMtYCnZJn0YhkziC0p+4B3h/f9xNqcvnTBFNvgn0jDPsE8kzWeFX+anlSd8s9hIf3pfss+ina6PcSmifyYSNcu8iHx5NmNuWZF/M8h9BuP4/QgWApFcz0XjRSP6lnFISLlN/JhlPPqAWEC6V576hyb6mUZjx5Jmu8Kn+1PM8lHNTzHm7E4RsZ3sMt7/H2UopecJtKw82kGc94pyvPYuJD/9z952b2ZZqgJhoRkZpSE42ISE0pwIuI1JQCvIhITSnAi4jUlAK8iEhN/X+cPEzGCaZRoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(np.std(X_train_pca, axis = 0)).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191    0.990123\n",
       "192    0.990671\n",
       "193    0.991193\n",
       "194    0.991700\n",
       "195    0.992199\n",
       "196    0.992689\n",
       "197    0.993150\n",
       "198    0.993589\n",
       "199    0.994012\n",
       "200    0.994427\n",
       "201    0.994819\n",
       "202    0.995196\n",
       "203    0.995569\n",
       "204    0.995918\n",
       "205    0.996259\n",
       "206    0.996577\n",
       "207    0.996889\n",
       "208    0.997184\n",
       "209    0.997439\n",
       "210    0.997673\n",
       "211    0.997905\n",
       "212    0.998124\n",
       "213    0.998302\n",
       "214    0.998466\n",
       "215    0.998620\n",
       "216    0.998763\n",
       "217    0.998892\n",
       "218    0.999014\n",
       "219    0.999121\n",
       "220    0.999222\n",
       "         ...   \n",
       "228    0.999737\n",
       "229    0.999779\n",
       "230    0.999816\n",
       "231    0.999848\n",
       "232    0.999875\n",
       "233    0.999900\n",
       "234    0.999925\n",
       "235    0.999948\n",
       "236    0.999964\n",
       "237    0.999979\n",
       "238    0.999987\n",
       "239    0.999993\n",
       "240    0.999998\n",
       "241    1.000000\n",
       "242    1.000000\n",
       "243    1.000000\n",
       "244    1.000000\n",
       "245    1.000000\n",
       "246    1.000000\n",
       "247    1.000000\n",
       "248    1.000000\n",
       "249    1.000000\n",
       "250    1.000000\n",
       "251    1.000000\n",
       "252    1.000000\n",
       "253    1.000000\n",
       "254    1.000000\n",
       "255    1.000000\n",
       "256    1.000000\n",
       "257    1.000000\n",
       "Length: 67, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained = pd.Series(np.cumsum(pca.explained_variance_ratio_))\n",
    "explained[explained>0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test: 0.8652875249593598\n",
      "R2 on train: 0.9242859253420233\n",
      "RMSE on test: 0.15955952570723062\n",
      "RMSE on train: 0.10533633318591275\n"
     ]
    }
   ],
   "source": [
    "target = \"SalesPrice\"\n",
    "X = df.drop(columns=[target]) # Features\n",
    "y = np.log(df[target]) # target variable\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True) # One hot encoding\n",
    "\n",
    "# Randomly split the data into training and test test. \n",
    "# Keeping 30% of the records in test set.\n",
    "# random_state creates a reproducible set of random samples \n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y\n",
    "                                , test_size = 0.3, random_state = 1)\n",
    "\n",
    "\n",
    "pipe = pipeline.Pipeline([\n",
    "    (\"poly\", preprocessing.PolynomialFeatures(degree=1, include_bias=False)),\n",
    "    (\"scaler\", preprocessing.StandardScaler()),\n",
    "    (\"pca\", decomposition.PCA(n_components=191)),\n",
    "    (\"estimator\", linear_model.Lasso(alpha=0.001, max_iter=2000)) \n",
    "    # alpha: regularization parameter\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "r2_test = metrics.r2_score(y_test, y_test_pred)\n",
    "r2_train = metrics.r2_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"R2 on test:\", r2_test)\n",
    "print(\"R2 on train:\", r2_train)\n",
    "\n",
    "print(\"RMSE on test:\", np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))\n",
    "print(\"RMSE on train:\", np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
